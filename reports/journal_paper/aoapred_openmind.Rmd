---
title: Consistency and variability in children's word learning across languages
short_title: Word learning consistency and variability

## 'OpenMind' or 'manuscript'
class_option: manuscript
## Only needed if you use 'manuscript' option
journal_name: Open Mind

author:
  - name          : Mika Braginsky
    affiliation   : 1
  - name          : Daniel Yurovsky
    affiliation   : 2
  - name          : Virginia A. Marchman
    affiliation   : 3
  - name          : and Michael C. Frank
    affiliation   : 3

affiliation:
  - code: 1
    address: Department of Brain and Cognitive Sciences, Massachusetts Institute of Technology
  - code: 2
    address: Department of Psychology, University of Chicago
  - code: 3
    address: Department of Psychology, Stanford University

corresponding_author:
  name: Mika Braginsky
  email: mikabr@mit.edu

short_author: Braginsky, Yurovsky, Marchman, Frank
supplements_links: |
  Links to Supplementary Materials.

keywords:
  - word learning
  - language acquisition
  - corpus analysis

abstract: |
  Why do children learn some words earlier than others? The order in which words are acquired can provide clues about the mechanisms of word learning. In a large-scale corpus analysis, we use parent-report data from over 32,000 children to estimate the acquisition trajectories of around 400 words in each of 10 languages, predicting them on the basis of independently-derived properties of the words' linguistic environment (from corpora) and meaning (from adult judgments). We examine the consistency and variability of these predictors across languages, by lexical category, and over development. The patterning of predictors across languages is quite similar, suggesting similar processes in operation. In contrast, the patterning of predictors across different lexical categories is distinct, in line with theories that posit different factors at play in the acquisition of content words and function words. By leveraging data at a significantly larger scale than previous work, our analyses identify candidate generalizations about the processes underlying word learning across languages.

acknowledgments: |
  Thank you to the labs and individuals who contributed data to Wordbank and to NSF BCS \#1528526 for support.

author_contributions: |
  M.B. and D.Y. conducted data processing and analysis, with supervision from V.A.M. and M.C.F.; all authors contributed to writing the paper.

biblio: aoapred
output:
  rticles::opmi_article:
    md_extensions: -citations-autolink_bare_uris-auto_identifiers-implicit_header_references
    includes:
      after_body: "aoapred_si.tex"

header-includes:
  - \usepackage{booktabs}
  - \usepackage{listings}
  - \lstset{literate={~} {$\sim$}{1}}
  - \lstset{basicstyle=\ttfamily}
---



```{r setup, child="setup.Rmd", cache=FALSE}
```

```{r model_checks, child="model_checks.Rmd"}
```


# Introduction

Despite tremendous individual variation in children's rate of development \citep{fenson2007}, the first words that they utter are strikingly consistent \citep{tardif2008,schneider2015}: they tend to talk about important people in their life ("mom", "dad"), social routines ("hi", "uh-oh"), animals ("dog", "duck"), and foods ("milk", "banana"). Even as children learn from their own experiences and according to their own interests \citep{mayor2014,nelson1973}, their vocabulary grows rapidly, typically adding more nouns, but also verbs ("go") and other predicates ("hot") to their repertoires. Over just their first three years, children learn hundreds, even thousands of words \citep{fenson1994,mayor2011}.

One classic approach to word learning focuses on the specific mechanisms that children bring to bear on the learning problem. For example, across many laboratory experiments, a variety of mechanisms have been identified as plausible drivers of early word learning, including co-occurrence based and cross-situational word learning \citep{schwartz1983,yu2007}; social cue use \citep{baldwin1993}; and syntactic bootstrapping \citep{gleitman1990,mintz2003}. The ability to identify which of these mechanisms is most explanatory has been challenging. Indeed, many theories of early word learning take multiplicity of cue types and mechanisms as a central feature (e.g., \citealp{hollich2000,bloom2000}). As important as this work is, though, these studies typically are aimed at understanding how one or a small handful of words are learned in the laboratory under precisely-defined learning conditions. They do not directly address questions regarding the developmental composition and ordering of growth in the lexicon across many different children in their natural environments, nor whether these patterns are consistent across different languages.

An alternate approach to early word learning asks why some words are learned so early and some much later. This question about the order of the acquisition of first words can provide a different window into the nature of children's language learning. Posed as a statistical problem, the challenge is to find what set of variables best predicts the age at which different words are acquired. Previous work using this approach has revealed that, in English, within a lexical category (e.g., nouns, verbs), words that are more frequent in speech to children are likely to be learned earlier \citep{goodman2008}. Further studies have found evidence that a variety of other semantic and linguistic factors are related to word acquisition, such as salience and iconicity \citep{hills2009,stokes2010,perry2015,roy2015,swingley2017}.

But these exciting findings are limited in their generality because each study used a different dataset and focused on different predictors. In addition, nearly all studies to date have exclusively analyzed data from English-learning children, providing no opportunity for cross-linguistic comparison of the relative importance of the many relevant factors under consideration. Cross-linguistic comparisons are critical to identifying the universal mechanisms that are in play for all children and differentiating them from patterns of acquisition that emerge due to the particulars of a given language or culture \citep{slobin1985,bates1987}. Our goal here is to extend these classic approaches by assessing the degree to which the predictors of word learning are consistent across different languages, as well as whether there are similar patterns across different lexical categories.

The primary tool for characterizing the breadth of children's early vocabularies in these previous studies has been structured parent report. Naturalistic language samples and experimental methods are both valuable methods for assessing aspects of child language \citep{bornstein1998,fernald2006}. But outside of a few ultra-dense transcripts (e.g., \citealp{roy2015}), neither method typically provides the kind of holistic and comprehensive view that comes from parent report. We focus in particular on the MacArthur-Bates Communicative Development Inventory (CDI; \citealp{fenson2007}), a family of parent-report vocabulary checklists in which parents are asked whether their child "understands" or "understands and says" a large set of individual words.

The CDIs are an inexpensive and widely-used method for gathering reliable and valid data about the nature and extent of young children's productive and receptive vocabularies (see \citealp{fenson1994} for review; cf. \citealp{feldman2000, fenson2000}). Although CDIs cannot exhaustively capture all words in a child's vocabulary \citep{mayor2011}, they do give an estimate of a child's knowledge about several hundred words, far more than the handful that are typically tested in a lab experiment. CDI estimates of vocabulary size are highly correlated with children’s overall vocabulary knowledge as assessed with naturalistic observation or using standardized tests \citep{fenson2007}. Of course, any parent report measure is subject to reporting biases. The CDIs were designed to minimize these by asking parents to report only on observable behaviors that are currently (rather than retrospectively) demonstrated and to identify words from a pre-selected list (rather than having them recall them on their own).

Because of the low cost of administering CDI instruments, it is relatively easy to gather samples containing data about hundreds or thousands of children. Such large samples in turn make it possible to recover stable estimates of the average difficulty of individual words, even if individual children's data may be noisy. Thus, CDI data are typically the dataset of choice for the studies of vocabulary composition described above.

Finally, CDI instruments have been adapted in dozens of different languages, providing an opportunity for cross-linguistic comparison. The American English CDI is not simply translated to other languages verbatim; instead, expert groups of researchers adapt the form for their particular linguistic and cultural situation. This process leads to a wide range of forms that share a common structure, but contain sets of words that are customized to a particular language and culture. Thus, cross-linguistic comparisons do not reflect children’s acquisition of a single set of words, but instead capture relevant information regarding patterns of children's vocabulary development using instruments designed specifically for each language.^[Of course, observational data of this type are still open to other sources of bias, a point we return to in the Discussion.]

In our study, we conduct cross-linguistic comparisons of the acquisition trajectories of children's early-learned words using Wordbank ([wordbank.stanford.edu](http://wordbank.stanford.edu); \citealp{frank2016}), an open repository that aggregates administrations of the CDI across languages. We integrate these acquisition trajectory data with independently-derived characterizations of the word learning environment from other datasets. The use of secondary datasets is warranted because no currently available resource provides data on both children's language environments and their learning outcomes for more than a small handful of children. In particular, we derive our estimates of the language environment from transcripts of speech to children in the CHILDES database \citep{macwhinney2000} and measures of meaning-related word properties from available psycholinguistic databases. This data-integration methodology was originated by \citet{goodman2008}; it relies on large samples to average out the (substantial) differences among children and care environments.  While introducing additional sources of variability, this approach allows for analyses that cannot be performed on smaller datasets that measure only children or environments but not both.

To measure environmental input, we used existing adult speech data from the CHILDES database to estimate each word's frequency (a) in speech to children, (b) as a sole utterance constituent, (c) in utterance-final position, and the (d) mean length of utterances (MLU) containing that word. While crude, these measures are both easy to compute and relatively comparable across languages. To derive proxies for the meaning-based properties of each word, we accessed available psycholinguistic norms using adult ratings of each word's (a) concreteness, (b) valence, (c) arousal, and (d) association with babies. Integrating these estimates, we predict each word's acquisition trajectory, assessing the relative contributions of each predictor, how predictors change over development, and how predictors differ by lexical category. Since vocabulary composition differs in comprehension and production (e.g., \citealp{benedict1979}), we conduct our analyses independently on each. 

These analyses address two questions. First, we ask about the degree of consistency across languages in the relative importance of each predictor. To do so, we compare the estimates for the effect of each predictor for each language and conduct analyses that determine the likelihood that the consistency of the estimates did not occur by chance. Consistency in the patterning of predictors would suggest that similar information sources are important for learners, regardless of language, and that linguistic dissimilarities (e.g., greater morphological complexity in Russian, greater phonological complexity in Danish) do not dramatically alter the course of acquisition. Conversely, evidence for variability across languages would show the degree to which learners face different challenges in learning different languages, posing a challenge for more universalist accounts. Further, systematicity in the variability between languages would reveal which languages are more similar than others in the structure of these different challenges.

Second, we ask which lexical categories are most influenced by linguistic environment factors, like frequency and utterance length, compared with meaning-based factors like concreteness and valence. Division of dominance theory suggests that nouns might be more sensitive to meaning factors, while predicates and closed-class words might be more sensitive to linguistic environment factors \citep{gentner2001}. And on syntactic bootstrapping theories \citep{gleitman1990}, nouns are argued to be learned via frequent co-occurrence (operationalized by frequency) while verbs might be more sensitive to syntactic factors (operationalized here by utterance length; \citep{snedeker2007}). Thus, examining the relative contribution of different predictors across lexical categories can help test the predictions of influential theories of acquisition.


# Methods

The code and data for these analyses are available at \href{https://github.com/mikabr/aoa-prediction}{github.com/mikabr/aoa-prediction}.

## Acquisition trajectories

To estimate the trajectory of words' acquisition, we used vocabulary data collected using CDI instruments adapted in many different languages, including both Words & Gestures (WG) and Words & Sentences (WS) forms. When filling out a CDI form, parents are either asked to indicate whether their child "understands" (comprehension) or "understands and says" (production) each of around 400-700 words. Both comprehension and production are queried for younger children and only production is queried for older children. We included data from the items on the WG form for comprehension, and data from the items in common between the WG and WS forms for production. Placeholder items, such as "child's own name," were excluded. Table\ \ref{tab:langstats} gives an overview of our acquisition data (\citealp{kovacevic1996,bleses2008,boudreault2007,trudeau2011,caselli2012,caselli1995,simonsen2014,vershinina2011,yeliseyeva2009,fenson2003,eriksson2002,acarlar2008}; also see SI Figure\ \ref{fig:age-dist} for the age distributions). Each of the datasets were collected in the language of the community, e.g., the Mexican Spanish CDI data were collected in several areas of Mexico; longitudinal administrations were excluded.

```{r lang_stats_table, child="lang_stats_table.Rmd"}
```

For each word, the CDI data yield a trajectory reflecting the number of children that are reported to understand or produce the word at each age covered by the instrument (see Figure\ \ref{fig:demotraj} for some examples).

```{r demotraj, fig.width=7, fig.height=3.5, fig.cap='Example production trajectories for the words "dog" and "jump" across languages. Points show the proportion of children producing each word for each one-month age group. Lines show the best-fitting logistic curve. Labels show the forms of the words in each language.'}
demo_lemmas <- c("dog", "jump")
 
demo_data <- uni_prop_data %>%
  ungroup() %>%
  filter(uni_lemma %in% demo_lemmas,
         measure == "produces") %>%
  mutate(language = language %>% str_remove(" \\(.*\\)"))

word_data <- demo_data %>%
  select(language, uni_lemma, items) %>%
  distinct(language, uni_lemma, .keep_all = TRUE) %>%
  unnest() %>%
  mutate(x = ifelse(uni_lemma == demo_lemmas[1], 8, 35),
         y = ifelse(uni_lemma == demo_lemmas[1], 1, 0))

ggplot(demo_data, aes(x = age, y = prop, colour = uni_lemma)) +
  facet_wrap(~language, ncol = 5) +
  geom_point(size = 0.8, alpha = 0.4) +
  geom_smooth(aes(weight = num_true + num_false), method = "glm",
              method.args = list(family = "binomial"),
              se = FALSE, size = 1) +
  geom_label(aes(x = x, y = y, label = definition), data = word_data, size = 3,
             label.padding = unit(0.15, "lines"), vjust = "inward",
             hjust = "inward", family = .family) +
  scale_colour_ptol(guide = FALSE) +
  scale_y_continuous(name = "Proportion of children producing") +
  scale_x_continuous(name = "Age (months)", breaks = seq(10, 30, 10))
```

## Word properties

### Overview

For each word in each of our `r num_langs` languages, we used corpora of child-directed speech in that language from CHILDES to obtain an estimate of its frequency, the mean length of utterances in which it appears, its frequency as the sole constituent of utterance, and its frequency in utterance final position. We also computed each word's length in phonemes.

In addition, each word's concreteness, valence, arousal, and relatedness to babies^[Previous studies have shown robust consistency in the types of words that children learn very early \citep{tardif2008}. These words seem to describe concepts that are important or exciting in the lives of infants in a way that standard psycholinguistic features like concreteness do not. Capturing this intuition quantitatively is difficult, but \citet{perry2015} provides a proxy measure as a first step. This measure is simply the degree to which a particular word was "associated with babies". Intuitively, we expect this measure to capture the degree to which words like "ball" or "bottle" feature heavily in the environment (and presumably, mental life) of many babies.] were compiled from ratings based on previous studies using adult raters. Since existing ratings are primarily available for English, we mapped all words onto translation equivalents across CDI forms, verified by native speaker judgement, allowing us to use the English ratings across languages. Of the resulting translation equivalent meanings, `r in_range(1, 1)`% occur only in one language, `r in_range(2, 9)`% occur in more than one but not all languages, and `r in_range(10, 10)`% occur in all languages. While necessarily imperfect, this method allows us to examine languages for which limited resources exist. Example words for these predictors in English are shown in Table\ \ref{tab:extremes} (also see SI Figures\ \ref{fig:pred-dist-raw} and \ref{fig:pred-dist-scaled} for the distributions of values of each predictor).

```{r extremes_table, child="extremes_table.Rmd"}
```

Each numeric predictor was centered and scaled (within language) so that all predictors would have comparable units.

### Frequency

For each language, we derived unigram counts based on all corpora in CHILDES for that language. Frequencies varied widely both within and across lexical categories (see SI Figure\ \ref{fig:freq-dist}). Each word's count was summed across inflected forms (e.g., "dogs" counts as "dog") and synonyms (e.g., "father" counts as "daddy"). For polysemous words (e.g., "orange" as in color or fruit), occurrences were split uniformly between the senses on the CDI (there were only between `r min(poly$n)` and `r max(poly$n)` such word pairs in the various languages; in the absence of cross-linguistic corpus resources for sense disambiguation, this is a necessary simplification). Counts were normalized to the length of each corpus, Laplace smoothed (i.e., counts of 0 were replaced with counts of 1), and log transformed.

### Solo and Final Frequencies

Using the same dataset as for frequency, we estimated the frequency with which each word occurred as the sole word in an utterance, and the final word of an utterance (not counting single-word utterances). Solo and final counts were normalized to the length of each corpus, Laplace smoothed, and log transformed. Since both of these estimates are by necessity highly correlated with frequency, we then residualized unigram frequency out of both, so that values reflect an estimate of the effects of solo frequency and final frequency over and above frequency.

### MLU

MLU is only a rough proxy for syntactic complexity, but is relatively straightforward to compute across languages (in contrast to other metrics). For each language, we estimated each word's MLU by calculating the mean length in words of the utterances in which that word appeared, for all corpora for that language. For words that occurred fewer than 10 times, MLU estimates were treated as missing.

### Number of phonemes

In the absence of consistent resources for cross-linguistic pronunciation, we computed the number of phonemes in each word in each language based on phonemic transcriptions of each word obtained using the eSpeak tool \citep{duddington2012}. We then spot-checked these transcriptions for accuracy. 

### Concreteness

We used previously collected norms for concreteness \citep{brysbaert2014}, which were gathered by asking adult participants to rate how concrete the meaning of each word is on a 5-point scale from abstract to concrete.

### Valence and Arousal

We also used previously collected norms for valence and arousal \citep{warriner2013}, for which adult participants were asked to rate words on a 1-9 happy-unhappy scale (valence) and 1-9 excited-calm scale (arousal).

### Babiness

We used previously collected norms of "babiness", a measure of association with infancy \citep{perry2015} for which adult participants were asked to judge a word's association with babies on a 1-10 scale.

### Lexical category

Category was determined on the basis of the conceptual categories presented on the CDI form (e.g., "Animals", "Action Words"), such that the Nouns category contains common nouns, Predicates contains verbs, adjectives, and adverbs, Function Words contains closed-class words (following \citealp{bates1994}), and the remaining items are binned as Other.

### Imputation

The resulting set of predictor value for each language had varying numbers of missing values, depending on resource availability (number phonemes 0%, concreteness 0%-1%, arousal and valence 8%-13%, [solo/final] frequency 2%-14%, babiness 10%-33%, MLU 2%-53%). We used iterative regression imputation to fill in these missing values by first replacing missing values with samples drawn randomly with replacement from the observed values, and then iteratively imputing values for a predictor based on a linear regression fitting that predictor from all others.

### Collinearity

A potential concern for comparing coefficient estimates is predictor collinearity. Fortunately, in every language, the only relatively high correlations were between MLU and solo frequency (mean over languages `r mean_pair_cor('MLU', 'solo_frequency')`), as expected given the similarity of these factors, along with modest correlations between frequency and concreteness (mean over languages `r mean_pair_cor('concreteness', 'frequency')`) and between frequency and number of phonemes (mean over languages `r mean_pair_cor('frequency', 'num_phons')`), a reflection of Zipf's Law \citep{zipf1935}. More importantly, the variance inflation factor for each predictor in each language was no greater than `r max(vifs$vif)`, indicating that multicollinearity among the predictors is low (see SI Figure\ \ref{fig:predictor-cors} for the full set of pairwise correlations and SI Figure\ \ref{fig:vifs} for the variance inflation factors).


## Analysis

We used mixed-effects logistic regression models (fit with the MixedModels package in Julia; \citealp{bates2018}) to predict whether each child understands/produces each word from the child's age, properties of the word, interactions between each property and age, and interactions between each property and lexical category (which was contrast coded). Each model was fit to all data from a particular language and included a random intercept for each word and a random slope of age for each word. Computational and technical limitations prevented us from including random effects for child or including data from all languages in one joint model.

The magnitude of the standardized coefficient on each property gives an estimate of its independent contribution to words being understood/produced by more children. Interactions between properties and age give estimates of how this effect is modulated for earlier-learned and later-learned words. For example, a positive effect of babiness means that words associated with babies are learned earlier; a negative interaction with age means that high babiness primarily leads to higher rates of production and comprehension for younger children. Similarly, interactions between properties and lexical category give estimates of how the effect differs among nouns, predicates, and function words.


# Results

```{r refcoefs, fig.width=7, fig.height=4.5, fig.cap="Estimates of coefficients in predicting words' developmental trajectories for English comprehension and production data. Larger coefficient values indicate a greater effect of the predictor on acquisition: positive main effects indicate that words with higher values of the predictor tend to be understood by more children, while negative main effects indicate that words with lower values of the predictor tend to be understood by more children; positive age interactions indicate that the predictor's effect increases with age, while negative age interactions indicate the predictor's effect decreases with age. Error bars indicates 95\\% confidence intervals; filled in points indicate coefficients for which $p < 0.05$."}
ggplot(ref_coefs, aes(x = estimate, y = term)) +
  facet_grid(language + measure ~ effect, scales = "free",
             labeller = as_labeller(label_caps)) +
  geom_pointrangeh(aes(colour = term, shape = fct_rev(signif),
                      xmin = estimate - 1.96 * std_error,
                      xmax = estimate + 1.96 * std_error)) +
  geom_vline(xintercept = 0, color = .grey, linetype = "dotted") +
  scale_colour_ptol(guide = FALSE) +
  scale_shape_manual(values = c(19, 21), guide = FALSE) +
  labs(y = "", x = "Coefficient estimate")
```

```{r langcoefs, fig.width=7, fig.height=4.5, fig.cap="Estimates of coefficients in predicting words' developmental trajectories for all languages and measures. Each point represents a predictor's coefficient in one language, with the bar showing the mean across languages. Filled in points indicate coefficients for which $p < 0.05$."}
ggplot(plt_lang_coefs, aes(x = estimate, y = term, colour = term)) +
  facet_grid(measure ~ effect, scales = "free",
             labeller = as_labeller(label_caps)) +
  geom_point(aes(shape = fct_rev(signif)), size = 1, alpha = 0.4) +
  stat_summaryh(geom = "crossbarh", fun.x = mean, fun.xmin = mean,
                fun.xmax = mean, fatten = 3) +
  geom_vline(xintercept = 0, color = .grey, linetype = "dotted") +
  scale_colour_ptol(guide = FALSE) +
  scale_shape_manual(values = c(19, 21), guide = FALSE) +
  labs(x = "Coefficient estimate", y = "")
```

### English predictor effects

To illustrate the structure of our analysis, we first describe the results for English data, shown in Figure\ \ref{fig:refcoefs} as the main effect and age interaction coefficient estimates and 95% confidence intervals, for comprehension and production. For main effects, words are more likely to be known by more children if they are higher in frequency or concreteness, as well as in babiness for comprehension and in sentence-final frequency or sole-constituent frequency for production. In contrast, words that appear in shorter sentences (MLU) are more likely to be reported as understood or produced. For age interactions, while most predictors have consistent effects over age, words that are higher in frequency or concreteness are more likely to be known more by older children, while words that are higher in valence have a greater effect on acquisition in younger children, with an additional negative interaction with babiness in comprehension and positive interaction with MLU in production.

### Cross-linguistic predictor effects

Figure\ \ref{fig:langcoefs} shows the coefficient estimate for each predictor in each language and measure (for additional visualizations of the coefficients, see SI Figures\ \ref{fig:by-lang-main}, \ref{fig:by-lang-age}, and \ref{fig:prod-comp-coefs}). We find that frequency is the strongest predictor of acquisition (mean across languages and measures `r mean_term_coef("frequency")`). Other relatively strong overall predictors include concreteness (`r mean_term_coef("concreteness")`), solo frequency (`r mean_term_coef("solo_frequency")`), MLU (`r mean_term_coef("MLU")`), and final frequency (`r mean_term_coef("final_frequency")`). Number of phonemes is comparatively large for production (`r mean_term_measure_coef("produces", "num_phons")`) but not comprehension (`r mean_term_measure_coef("understands", "num_phons")`); conversely, babiness is comparatively large for comprehension (`r mean_term_measure_coef("understands", "babiness")`) but not production (`r mean_term_measure_coef("produces", "babiness")`). Finally, valence (`r mean_term_coef("valence")`) and arousal (`r mean_term_coef("arousal", 3)`) have much smaller effects.

Given the emphasis on frequency effects in the literature \citep{ambridge2015}, one might have expected frequency to dominate, but several other predictors are also quite strong. In addition, some factors previously argued to be important for word learning, namely valence and arousal \citep{moors2013}, appear to have limited relevance when compared to other factors. These results provide a strong argument for our approach of including multiple predictors and languages in our analysis.

```{r consistency, fig.width=6, fig.height=3, fig.cap="Correlations of coefficient estimates between languages. Each point represents the mean of one language's coefficients' correlation with each other language's coefficients, with the vertical line indicating the overall mean across languages. The shaded region and line show a bootstrapped 95\\% confidence interval of a randomized baseline where predictor coefficients are shuffled within language."}
ggplot(plt_coef_summary, aes(x = mean_cor, y = language)) +
  facet_grid(. ~ measure, labeller = as_labeller(label_caps)) +
  geom_vline(aes(xintercept = mean_cor), colour = .grey, size = 0.4,
             data = plt_coef_summary %>% group_by(measure) %>%
               summarise(mean_cor = mean(mean_cor))) +
  geom_point(aes(colour = language), size = 2) +
  geom_rect(aes(xmin = ci_lower_cor, xmax = ci_upper_cor,
                ymin = as.numeric(language) + 0.4,
                ymax = as.numeric(language) - 0.4,
                fill = language),
            data = plt_baseline_coef_summary,
            alpha = .2, linetype = 0) +
  geom_segment(aes(x = mean_cor, xend = mean_cor,
                y = as.numeric(language) + 0.4,
                yend = as.numeric(language) - 0.4),
            data = plt_baseline_coef_summary,
            colour = .grey) +
  scale_x_continuous(breaks = seq(0, 1, 0.2)) +
  labs(x = "Mean correlation with other languages' coefficients",
       y = "") +
  scale_colour_ptol(guide = FALSE) +
  scale_fill_ptol(guide = FALSE)
```

```{r clustering, fig.width=5, fig.height=3.5, out.width="70%", fig.cap="Dendrograms of the similarity structure among languages' coefficients."}
coef_clust_segments <- coef_clust %>%
  mutate(segment = map(clust, ~.x %>% segment())) %>%
  select(-data, -clust) %>%
  unnest()

typology <- yaml::read_yaml("typology.yaml") %>%
  data_frame(label = names(.), family = unlist(.)) %>%
  select(label, family)

coef_clust_labels <- coef_clust %>%
  mutate(segment = map(clust, ~.x %>% label())) %>%
  select(-data, -clust) %>%
  unnest() %>%
  mutate(label = label %>% str_remove(" \\(.*\\)")) %>%
  left_join(typology)

plt <- ggplot(coef_clust_segments) +
  facet_grid(. ~ measure, scales = "free",
             labeller = as_labeller(label_caps)) +
  geom_segment(aes(x = x, y = y, xend = xend, yend = yend)) +
  geom_text(aes(x = x, y = y - 0.02, label = label, colour = family),
            data = coef_clust_labels, hjust = 0, family = .family) +
  coord_flip() +
  scale_x_reverse() +
  scale_y_reverse() +
  scale_colour_ptol(name = "Language family",
                    guide = guide_legend(title.position = "top",
                                         title.hjust = 0.5,
                                         override.aes = list(size = 0),
                                         keyheight = unit(0, "lines"))) +
  expand_limits(y = -1) +
  theme_get() +
  theme(axis.line = element_blank(),
        axis.text = element_blank(),
        axis.ticks = element_blank(),
        axis.title = element_blank(),
        legend.position = "bottom",
        legend.text = element_blank(),
        legend.title = element_text(size = rel(0.8), margin = margin(b = -8)),
        legend.margin = margin(t = 0))

lgnd <- typology %>% distinct(family) %>% mutate(x = scale(1:n())) %>%
  ggplot(aes(x = x, y = 0)) +
    geom_text(aes(label = family, colour = family), family = .family, size = 3) +
    scale_colour_ptol(guide = FALSE) +
    lims(x = c(-3, 3)) +
    theme_void()

plot_grid(plt, lgnd, ncol = 1, rel_heights = c(20, 1))
```

```{r lexcatcoefs, fig.width=7, fig.height=4, fig.cap="Estimates of effect in predicting words' developmental trajectories for each language, measure, and lexical category (main effect of predictor + main effect of lexical category + interaction between predictor and lexical category). Each point represents a predictor's effect in one language, with the bar showing the mean across languages."}
ggplot(plt_lexcat_coefs, aes(x = estimate, y = term, colour = term)) +
  facet_grid(measure ~ lexical_category,
             labeller = as_labeller(label_caps)) +
  geom_point(size = 1, alpha = 0.4) +
  stat_summaryh(geom = "crossbarh", fun.x = mean, fun.xmin = mean,
                fun.xmax = mean, fatten = 3) +
  geom_vline(xintercept = 0, color = .grey, linetype = "dotted") +
  scale_colour_ptol(guide = FALSE) +
  labs(x = "Coefficient estimate", y = "")
```

### Consistency

Apart from valence and arousal, all other predictors have the same the direction of effect in all or almost all languages and measures (at least `r most_opposite(c("arousal", "valence"))` of the `r num_langs * 2`). Thus, across languages, words are likely to be understood and produced by more children if they are more frequent, shorter, more concrete, more frequently the only word in an utterance, more associated with babies, more frequently the final word in an utterance, and appear in shorter utterances.

Additionally, there is considerable consistency in the magnitudes of predictors across languages. A priori it could have been the case that different languages have wildly different effects of various factors (due to linguistic or cultural differences), but this pattern is not what we observe. Instead, there is more consistency in the correlations between coefficients across languages than would be expected by chance. As shown in Figure\ \ref{fig:consistency}, each language's mean pairwise correlation with other languages' coefficients (i.e., the correlation of coefficients for English with coefficients for Russian, for Spanish, and so on) is outside of bootstrapped estimates in a randomized baseline created by shuffling predictor coefficients within language. The pairwise correlations are more consistent for production (mean `r mean(filter(plt_coef_summary, measure == "produces")$mean_cor)`) than for comprehension (mean `r mean(filter(plt_coef_summary, measure == "understands")$mean_cor)`), in which French and Russian effects are more idiosyncratic.

### Variability

While some particular coefficients differ substantially from the trend across languages (e.g., the effect of frequency for comprehension in Spanish is near 0), these individual datapoints are difficult to interpret. Many unmeasurable factors could potentially account for these differences: Spanish frequency estimates could be less accurate due to corpus sparsity or idiosyncrasy, the samples of children in the Spanish CDI or CHILDES data could differ more demographically, or Spanish-learning children could in fact rely less on frequency. Rather than attempting to interpret individual coefficients, we instead ask how the patterns of difference among languages reflect systematic substructure in the variability of the effects. 

To examine the substructure of predictor variability, we used hierarchical clustering analysis to find the similarity structure among the pairwise correlations between languages' predictors. The resulting dendrograms are shown in Figure\ \ref{fig:clustering}, which broadly reflect language typology, especially for production data. This result suggests that some language-to-language similarity is captured by the profile of coefficient magnitudes our analysis returns. 

### Comprehension vs. production

As mentioned above, word length is the one predictor of acquisition that varied substantially between measures: it is far more predictive for production than comprehension. Thus, as measured here, length seems to reflect effects of production constraints (i.e., how difficult a word is to say) rather than comprehension constraints (i.e., how difficult it is to store or access). This result may explain why the hierarchical clustering analysis above appears more similar to linguistic typology in production than comprehension, that is, the role of production difficulty may be more similar for more typologically-related languages. Another possibility is that since the measures are confounded with age (comprehension is only measured for younger children), word length may play a larger role later in acquisition. Similarly, the stronger effect of babiness in comprehension over production could be due to its larger prominence earlier in development.

### Developmental change

For both comprehension and production, positive age interactions can be seen in at least 9 out of 10 languages for concreteness and frequency. Conversely, there are negative age interactions for babiness and valence for comprehension in at least 9 out of 10 languages. This suggests that concreteness and frequency facilitate learning more so later in development, while babiness and valence facilitate learning earlier in development. This result is consistent with the speculation above that the babiness predictor captures meanings that have special salience to very young infants.

### Lexical categories

Previous work suggests that predictors' relationship with age of acquisition differs among lexical categories \citep{goodman2008}. We investigate these differences by including lexical category interaction terms in our model. Figure\ \ref{fig:lexcatcoefs} shows the resulting effects for each lexical category, combining the main effect of a given predictor with the main effect of the lexical category and the interaction between that predictor and that lexical category (see also SI Figures\ \ref{fig:by-lexcat1} and \ref{fig:by-lexcat2}).

Across languages, the strongest predictors of acquisition for both nouns and predicates are concreteness (nouns `r mean_lexcat_coef("concreteness", "nouns")`; predicates `r mean_lexcat_coef("concreteness", "predicates")`) and frequency (nouns `r mean_lexcat_coef("frequency", "nouns")`; predicates `r mean_lexcat_coef("frequency", "predicates")`). Thus content words are most likely to be known by more children if they are more frequent or more concrete. Conversely, function words are most influenced by number of phonemes (`r mean_lexcat_coef("num_phons", "function_words")`), babiness (`r mean_lexcat_coef("babiness", "function_words")`), and MLU (`r mean_lexcat_coef("MLU", "function_words")`), meaning that function words are most likely to be known by more children if they are shorter, less associated with babies, or appear in shorter sentences. These patterns are supportive of the hypothesis that different word classes are learned in different ways, or at least that the bottleneck on learning tends to be different, leading to different information sources being more or less important across categories.

Additionally, the mean pairwise correlation of coefficients between languages is much larger for nouns (`r lexcat_mean_cor("nouns")`) and predicates (`r lexcat_mean_cor("predicates")`) than for function words (`r lexcat_mean_cor("function_words")`). The higher between-language variability for function words suggests the learning processes differ substantially more across languages for function words than they do for content words (see SI Figure\ \ref{fig:lexcat-consistency}).

# Discussion

What makes words easier or harder for young children to learn? Previous experimental work has largely addressed this question using small-scale lab studies. While such experiments can identify sources of variation, they typically do not allow for different sources to be compared directly. In contrast, observational studies allow the effects of individual factors to be measured across ages and lexical categories (e.g., \citealp{goodman2008,hills2009,swingley2017}), but are limited in the size and scope of the datasets and languages that can be directly compared. The current analyses take advantage of recent innovative approaches via Wordbank, a large, cross-linguistic dataset of parent report instruments. By compiling data regarding early lexical development across `r num_langs` languages and examining patterns of acquisition in relation to `r num_coefs` predictors, our work expands the scope of these studies dramatically, leading to several new findings.

First, we found consistency in the patterning of predictors across languages at a level substantially greater than the predictions of a chance model. This consistency supports the idea that differences in culture or language structure do not lead to fundamentally different acquisition strategies, at least at the level of detail we were able to examine. Instead, they are likely produced by processes that are similar across populations and languages. Such processes could include learning mechanisms or biases internal to children, or interactional dynamics between children or caregivers. We believe these consistencies should be an important topic for future investigation.

Second, predictors varied substantially in their weights across lexical categories. Frequent, concrete nouns were learned earlier, consistent with theories that emphasize the importance of early referential speech (e.g., \citealp{baldwin1995}). For predicates, concreteness was somewhat less important and frequency some more important. And for function words, length and MLU was more predictive, perhaps because it is easiest to decode the meanings of function words that are used in short sentences (or because such words have meanings that are easiest to decode). Overall, these findings are consistent with some predictions of both division of dominance theory, which highlights the role of conceptual structure in noun acquisition \citep{gentner2001}, and syntactic bootstrapping theory, which emphasizes linguistic structure over conceptual complexity in the acquisition of lexical categories other than nouns \citep{snedeker2007}. More generally, our methods here provide a way forward for testing the predictions of these theories across languages and at the level of the entire lexicon rather than individual words.

In addition to these new insights, several findings emerged that confirm and expand previous reports. Environmental frequency was an important predictor of learning, with more frequently-heard words learned earlier \citep{goodman2008,swingley2017}. Predictors also changed in relative importance across development. For example, certain words whose meanings were more strongly associated with babies appeared to be learned early for children across the languages in our sample (as in \citealp{tardif2008}). Finally, word length showed a dissociation between comprehension and production, suggesting that challenges in production do not carry over to comprehension (at least in parent-report data).

Despite its larger scope, our work shares a number of important limitations with previous studies. First and foremost, our approach is to predict one set of individuals with data about the experience of a completely different set and conceptual ratings gathered from yet others. In contrast to dense-data analyses \citep{roy2015}, this approach fundamentally limits the amount of variability we will be able to capture. Second, the granularity of the predictors that can be extracted from corpus data and applied to every word is necessarily quite coarse. Ideally, predictors could be targeted more specifically at particular theoretical constructs of interest (e.g., the patterns of use for specific predicates). Third, our analyses are conducted within language, so to the extent that the predictors can have differing ranges in different languages, cross-linguistic patterns in predictor effects could be obscured.

Finally, our data are observations gleaned from parent report. CDI instruments are both reliable and valid, and the cross-linguistic adaptations we used contain the original researchers' best attempts to create culturally-appropriate word lists. Nevertheless, this observational design introduces many sources of uncertainty and bias. First, the open data format of Wordbank reflects the sampling and administration methods of many groups around the world; these introduce many unknown biases that we cannot control (though they would likely not contribute to observed consistencies). Second, language and culture co-vary completely in our sample and so variability that we observe cannot be attributed to one or the other. Finally, some observed consistencies could arise from consistency in parental reporting biases. For example, across languages, parents might be generally biased to under-report comprehension of function words. Despite the quantity of data analyzed here, our conclusions will require further testing through converging evidence from both laboratory experiments and direct observation.

In sum, by examining predictors of early word learning across languages, we identified substantial cross-linguistic consistency in the factors contributing to the ease or difficulty of learning individual words. This suggests that common learning mechanisms and/or environmental supports for learning are shared across all of these languages. These findings also testify to the importance of building open, shared resources in the study of child language learning -- without the efforts of many research groups across many language communities, such studies would be impossible. Additionally, we hope that our work here provides a baseline for the building of future predictive models that allow theories of language learning to be tested at scale.

```{r si, results='hide', cache=FALSE}
# rmarkdown::render("aoapred_si.Rmd", quiet = TRUE)
```
