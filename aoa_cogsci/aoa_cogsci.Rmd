---
title: |
  | From _uh-oh_ to _tomorrow_
  | Predicting age of acquisition for early words across languages
bibliography: library.bib
csl: apa6.csl
document-params: "10pt, letterpaper"

author-information: > 
    \author{{\large \bf Mika Braginsky} \\ \texttt{mikabr@stanford.edu} \\ Department of Psychology \\ Stanford University
    \And {\large \bf Daniel Yurovsky} \\ \texttt{yurovsky@stanford.edu} \\ Department of Psychology \\ Stanford University
    \And {\large \bf Virginia A. Marchman} \\ \texttt{marchman@stanford.edu} \\ Department of Psychology \\ Stanford University
    \And {\large \bf Michael C. Frank} \\ \texttt{mcfrank@stanford.edu} \\ Department of Psychology \\ Stanford University}

abstract: 
    "Why do children learn some words earlier than others?  Regularities in the age of acquisition (AoA) of words across development and languages yield insights regarding the mechanisms guiding word learning. In a large-scale corpus analysis, we predict the age at which ~10,000 children learn 400 words in 7 languages from independently-derived linguistic, environmental, and conceptual factors. Predictors were not uniformly strong across development and varied as a function of lexical category (e.g., concreteness predicted nouns while linguistic structure predicted function words).  Moreover, there was evidence for cross-language consistency in predictor strength.  By leveraging data at a significantly larger scale than previous work, our analyses highlight both the power that emerges from unifying previously disparate theories, but also the amount of reliable variation that still remains unexplained."
    
keywords:
    "language acquisition; word learning; development"
    
output: cogsci2016::cogsci_paper
---

```{r global_options, include=FALSE}
knitr::opts_chunk$set(fig.width = 3, fig.height = 3, fig.crop = F,
                      fig.pos = "tb", fig.path = 'figs/', echo = F,
                      warning = F, cache = F, message = F, sanitize = T)
```

```{r, libraries}
library(knitr)
library(png)
library(grid)
library(xtable)
library(ggplot2)
library(langcog)
library(dplyr)
library(tidyr)
library(purrr)
library(ggrepel)
# library(extrafont)
# loadfonts(quiet = TRUE)
font <- "Times"
theme_set(theme_mikabr(base_size = 12, base_family = font) +
            theme(legend.key = element_blank(),
                  legend.background = element_rect(fill = "transparent"),
                  legend.margin = unit(0, "mm"),
                  panel.background = element_blank(),
                  panel.margin = unit(1, "mm"),
                  plot.margin = unit(c(0, 0, 0, 0), "mm")))
```

```{r}
# ----------
# to run and cache all the AoA prediction computation:
# - set working directory to this file's location
# - uncomment and run these four lines
# ----------
# setwd("..")
# knit("aoa_prediction_funs.Rmd", tangle = TRUE)
# source("aoa_prediction_funs.R")
# save.image("aoa_prediction.RData")

# when knitting, just uses cache
load("../aoa_prediction.RData")
```

# Introduction

Word learning is one of the central challenges of language acquisition. Learners must integrate multiple information sources to map the word forms they hear onto representations of their meanings. Across many laboratory experiments and small-scale models, a number of strategies have emerged as plausible components of word learning, including tracking co-occurrence statistics between words and referents to deduce word meaning across situations; attending to social cues like pointing and eye gaze; relying on biases, such as a basic level category bias; drawing on knowledge of relations between words to use known meanings to learn new ones; and so on.

Each of these strategies have been reliably demonstrated in the constrained learning context of the laboratory, indicating that they are possible parts of the word learning process. Small-scale experimental studies typically do not tell us whether these strategies operate uniformly across children, ages, and languages, however. It is also difficult to explore how strategies interact to create the longer-term dynamics of vocabulary acquisition. How do the various strategies differ in their relative contributions? And how does their influence change over the course of development?

Our approach to addressing these questions is to use large-scale vocabulary development data to examine these interactions. We can look across children to determine how easy or hard various words are to learn, and then examine the relation between word difficulty and features that differentiate words according to different strategies. For example, distributional learning strategies rely critically on frequency. Thus, to make a first assessment of the importance of distributional learning, we can examine the relationship between the age at which words are typically acquired and word frequency in child-directed speech. 

Indeed, work using such an approach has revealed that in English, within lexical category, words that are more frequent in speech to children are likely to be learned earlier [@goodman2008; @roy2009]. Further studies have found evidence for semantic networks [@hills2009], neighborhood density [@stokes2010], iconicity [@perry2015], and linguistic distinctiveness [@roy2015] as predictors of age of acquisition (AoA), suggesting that they are likely contributors to vocabulary development at scale. But these exciting findings are nevertheless limited in their generality because they used different datasets, focused on different predictors, and for the most part, only analyzed English data. It is thus impossible to compare the relative importance of the many relevant factors under consideration and to draw robust conclusions. 

To remedy this issue, we present analyses based on data from Wordbank ([wordbank.stanford.edu](http://wordbank.stanford.edu)), an open repository of cross-linguistic language development data [@frankinpress]. By aggregating administrations of the MacArthur-Bates Communicative Development Inventory [CDI; @fenson2007], a family of parent-report vocabulary checklists, Wordbank provides large-scale vocabulary data based on analogous instruments from more than 40,000 children in 14 different language communities. As such, Wordbank offers a novel resource for richer and more powerful analyses of vocabulary learning over development and across languages.

We integrate AoA estimates from Wordbank with characterizations of the word learning environment from the CHILDES database [@macwhinney2000] and elsewhere, a multiple data source approach originated by @goodman2008. Building on this work, we examine interactions between a variety of both environmental and conceptual factors. Using this same approach on a high-density longitudinal corpus for a single English-acquiring child, Roy et al. found that the length, usage frequency, and mean length of the utterances in which it occurred were all predictors of a word's AoA. But due to the nature of the dataset, this analysis used production-based AoA estimates and was further limited by relying on data from only one child (and hence one language). 

Our approach provides a complimentary analysis by using CDI comprehension data available in Wordbank to look at a common set of the earliest words that children learn across several different languages. We estimate AoA for around 400 words from CDIs in each of `r length(unique(lang_coef$language))` languages. We also estimate each word's frequency and mean length of utterance (MLU) based on the sentences in which it appears in CHILDES. We also obtain ratings of each word's concreteness, valence, arousal, and relevance to babies from previously collected norms. We use these measures to predict each word's AoA, assessing the relative contributions of each, as well as how predictors change over development and their interactions with lexical category. Each of these analyses has the potential to provide leverage on long-standing theoretical questions. 

A first theoretical question of interest is which lexical categories are most influenced by input-related factors like frequency and utterance length, compared with conceptual factors like concreteness or valence. For example, the "division of dominance" theory suggests that nouns might be more sensitive to cognitive factors while predicates and closed-class words might be more sensitive to linguistic factors [@gentner2001]. On the other hand, on syntactic bootstrapping theories [@gleitman1990], nouns are argued to be learned via frequent co-occurrence (operationalized by frequency) while verbs might be more sensitive to syntactic factors (operationalized here by utterance length), and neither would be particularly sensitive to conceptual complexity [@snedeker2007]. 

A second question of interest is the extent to which there is variability across languages in the relative importance of predictors. For example, are there differences in the importance of syntactic factors in morphologically more complex languages like Russian and Turkish, compared with simpler ones like English? Differences of this type might be revealing of the degree to which learners face different challenges in different language environments. Or consistency may suggest the operation of similar learning mechanisms and strategies that are not as dependent on the complexities of phonology, morphology, and syntax in a particular language. 

Overall, by incorporating a variety of theoretically-important factors, as well as basing our analysis on a large samples of words and children and building towards more cross-linguistic coverage, our study presents a more thorough investigation of the question of what properties determine words' learnability.

# Data

We use Wordbank, an open database of developmental vocabulary data, to estimate the age of acquisition for words across `r length(unique(lang_coef$language))` languages: `r paste(unique(lang_coef$language), collapse = ", ")`. We then ask what factors are most important for predicting this age of acquisition. Table 1 gives an overview of our data sources.

\setlength\tabcolsep{3pt}

```{r lang_stats, results="asis"}
library(wordbankr)
num_admins <- get_administration_data(mode = "local") %>%
  filter(form == "WG") %>%
  group_by(language) %>%
  summarise(num_admins = n())

# num_words <- words %>%
#   group_by(language) %>%
#   summarise(num_words = n())

aoa_stats <- crossling_model_data %>%
  group_by(language) %>%
  summarise(num_included = n())
            #mean_aoa = mean(aoa),
            #var_aoa = var(aoa))

childes_stats <- read.csv("../predictors/frequency/num_words.csv") #%>%
  #mutate(num_words = formatC(num_words, big.mark = ","))

lang_stats <- aoa_stats %>%
  #left_join(num_words) %>%
  left_join(num_admins) %>%
  left_join(childes_stats)
colnames(lang_stats) <- c("Language", "CDI Items", "CDI Admins", "CHILDES Words")
                          #"Mean AoA",, "Var AoA")

lang_table <- xtable(lang_stats, digits = 2, caption = "Dataset statistics")

print(lang_table, type = "latex", comment = FALSE, include.rownames = FALSE,
      table.placement = "ht", format.args = list(big.mark = ","))
```

## Estimating Age of Acquisition

To estimate the age at which words are acquired, we took vocabulary data collected using the MacArthur-Bates Communicative Development Inventory, specifically the Words & Gestures (infant) form for 8- to 18-month-olds. When filling out a CDI form, parents are asked to indicate whether their child understands and/or says each of around 400 words. From these data, for each word on the CDI, we computed the proportion of children at each age who are reported to understand the word. We then fit a logistic curve to these proportions using a robust generalized linear model (using the \texttt{robustbase} package in \texttt{R}) and determine when the curve crosses 0.5, i.e. at what age at least 50% of children are reported to understand the word. Following @goodman2008, we take this point to be each word's age of acquisition (AoA).

\setlength\tabcolsep{1pt}

```{r extremes, results="asis"}
num_extremes <- 3
extremes <- crossling_model_data %>%
    split(.$language) %>%
    map_df(function(lang_data) {
    map_df(c("aoa", rev(levels(crossling_predictors_ordered))), function(predictor) {
      highest <- lang_data %>%
        arrange_(as.formula(sprintf("~desc(%s)", predictor))) %>%
        .$uni_lemma %>%
        .[1:num_extremes]
      lowest <- lang_data %>%
        arrange_(predictor) %>%
        .$uni_lemma %>%
        .[1:num_extremes]
      return(data.frame("language" = unique(lang_data$language),
                        "Measure" = predictor,
                        "min" = paste(lowest, collapse = ", "),
                        "max" = paste(highest, collapse = ", ")))
    })
  }) %>%
  filter(language == "English") %>%
  select(-language) %>%
  mutate(order = row_number()) %>%
  gather(Value, Words, min, max) %>%
  arrange(order) %>%
  select(-order) %>%
  mutate(Measure = unlist(transpose(list(unique(Measure), rep("", length(Measure))))))

extremes[which(extremes$Measure == "num_characters") + 1, "Measure"] <- "characters"
extremes[which(extremes$Measure == "num_characters"), "Measure"] <- "num"

extremes_table <- xtable(extremes, label = "tab:mytable", align = "llcl",
                         #align = "llp{1in}p{1in}",
                         caption = "Examples of words with the lowest and highest values for age of acquisition and each predictor.")

print(extremes_table, type = "latex", comment = FALSE, include.rownames = FALSE,
      table.placement = "hb", floating.environment = "table")
```

```{r data, fig.height=6, fig.width=7, fig.env='figure*', fig.align='center', dev='cairo_pdf', fig.cap='Relationship between predictors and AoA for each lexical category in each language. Each point represents a word, with lines indicates linear model fits for each lexical category (in colors) and overall (in black).'}
crossling_model_data %>%
  gather_("predictor", "value", crossling_predictors) %>%
  mutate(predictor = factor(predictor, levels = crossling_predictor_levels),
         lexical_category = factor(lexical_category,
                                   labels = paste(levels(lexical_category), "  "))) %>%
  #filter(language %in% c("English", "Italian", "Norwegian")) %>%
  ggplot(aes(x = value, y = aoa)) +
    #facet_wrap(~predictor, ncol = 4) +
    facet_grid(language ~ predictor, scales = "free_x") +
    geom_point(aes(fill = lexical_category), colour = NA,
               size = 0.5, alpha = 0.4, shape = 21) +
    geom_smooth(aes(colour = lexical_category), method = "lm", se = FALSE, size = 0.8) +
    geom_smooth(color = "black", method = "lm", se = FALSE, size = 0.8) +
    scale_colour_solarized(name = "") +
    scale_fill_solarized(name = "") +
    xlab("Predictor Z-score") +
    scale_y_continuous(name = "Age of Acquisition (months)",
                       breaks = seq(5, 25, 5)) +
    #theme_mikabr(base_size = 10) +
    theme(legend.position = "top")
```

```{r}
predict_english <- function(english_predictors) {
  english_model_data <- english_model_data_fun(english_data_fun(uni_joined,
                                                                english_predictors,
                                                                num_characters),
                                               english_predictors)
  english_predictions_fun(english_model_data,
                          english_model_fun(english_model_data, english_predictors))
}
english_predictors <- c("frequency",  "concreteness", "num_characters",
                        "valence", "arousal", "babiness")
predictions <- predict_english(english_predictors)
predictions <- predictions %>%
    mutate(lexical_category = factor(lexical_category,
                                     levels = levels(lexical_category),
                                     labels = paste0(levels(lexical_category), "  ")),
           error = abs(predicted_aoa - aoa))

cors <- predictions %>%
  group_by(lexical_category) %>%
  summarise(cor = cor(aoa, predicted_aoa))
```

```{r fit, fig.height=2.3, fig.width=7, fig.env='figure*', fig.align='center', dev='cairo_pdf', fig.cap='Comparison between the model predicted and actual ages of acquisition for words in English. Words with an absolute error above 5 months are labelled for reference.'}
threshold <- 5
predictions %>%
  ggplot(aes(x = predicted_aoa, y = aoa)) +
    facet_wrap(~lexical_category, ncol = 4) +
    geom_point(aes(colour = lexical_category), size = 0.5) +
#     geom_point(aes(colour = lexical_category), size = 0.7,
#                data = filter(predictions, error < threshold)) +
    geom_text_repel(aes(label = uni_lemma, colour = lexical_category), size = 2,
                    family = font, data = filter(predictions, error >= threshold),
                    force = 27, max.iter = 1e5) + 
  # , label.padding = unit(0.15, "lines")) +
#     geom_label(aes(label = uni_lemma, colour = lexical_category), family = font,
#                     show.legend = FALSE, data = filter(predictions, error >= threshold),
#                     label.padding = unit(0.15, "lines"), size = 3) +
    geom_smooth(aes(colour = lexical_category), weight = 1, method = "lm", se = FALSE) +
    geom_smooth(colour = "black", weight = 2, method = "lm") +
    scale_colour_solarized(name = "", guide = FALSE) +
    scale_x_continuous(name = "Model Predicted AoA (months)",
                       breaks = seq(5, 25, by = 5), limits = c(5, 25)) +
    scale_y_continuous(name = "AoA (months)",
                       breaks = seq(5, 25, by = 5), limits = c(5, 25)) +
    geom_text(aes(x = 8, y = 24.5, label = sprintf("r = %.2f", cor)),
              data = cors, family = font, size = 2.8)
```

```{r devo, fig.height=3, fig.width=3, fig.env='figure', fig.align='center', fig.pos='!hb', dev='cairo_pdf', fig.cap='Predictor values over development, with a cubic curve smoothing over all items in all languages.'}
crossling_data %>%
  gather_("predictor", "value", crossling_predictors) %>%
  filter(!is.na(value)) %>%
  mutate(predictor = factor(predictor, levels = crossling_predictor_levels,
                            labels = paste(crossling_predictor_levels, " "))) %>%
  ggplot(aes(x = aoa, y = value, colour = predictor)) +
    #facet_wrap(~predictor, ncol = 4) +
    #geom_point(size = 0.5, alpha = 0.2) +
    #geom_smooth(method = "loess", se = FALSE, span = 0.75) +
    geom_hline(yintercept = 0, color = "grey", linetype = "dashed") +
    geom_smooth(method = "lm", formula = y ~ poly(x, 3), se = FALSE) +
    scale_colour_solarized(name = "", guide = guide_legend(nrow = 4, byrow = FALSE)) +
    scale_x_continuous(name = "Age of Acquisition (months)",
                       breaks = seq(0, 30, 5)) +
    scale_y_continuous(name = "Predictor Z-score",
                       breaks = seq(-1.5, 1.5, 0.5)) +
    theme(legend.position = c(0.64, 0.13),
          legend.direction = "horizontal",
          legend.key.height = unit(0.7, "lines"),
          legend.key.width = unit(0.7, "lines"),
          legend.text = element_text(size = 8))
```

```{r coefs, fig.height=3.5, fig.width=7, fig.env='figure*', fig.align='center', dev='cairo_pdf', fig.cap='Estimates of predictor coefficients by language and for the all language model. Values above 0 indicate a positive relationship (i.e. words with higher MLU tend to have a higher AoA), while values below 0 indicate a negative relationship (i.e. words with higher frequency tend to have a lower AoA.'}
plot_coefs <- crossling_coef %>%
  mutate(language = "All Languages") %>%
  bind_rows(lang_coef) %>%
  mutate(language = factor(language, levels = c("All Languages", langs)),
         term = factor(term, levels = rev(levels(term))),
         sign = factor(sign(estimate)))

ggplot(plot_coefs, aes(x = term, y = estimate)) +
  facet_wrap(~language, ncol = 4) +
  geom_rect(data = filter(plot_coefs, language == "All Languages"),
            aes(fill = language), xmin = -Inf, xmax = Inf,
            ymin = -Inf, ymax = Inf, alpha = 0.03) +
  geom_pointrange(aes(ymin = estimate - 1.96 * std.error,
                      ymax = estimate + 1.96 * std.error,
                      colour = term)) +
  geom_hline(yintercept = 0, color = "grey", linetype = "dashed") +
  geom_text(aes(label = paste("bar(R)^2==", adj_rsq)), parse = TRUE,
            x = 7, y = 1.1, family = font, size = 2.8,
            data = data.frame(language = names(all_adj_rsq),
                              adj_rsq = round(unlist(all_adj_rsq), 2),
                              row.names = NULL)) +
  coord_flip() +
  scale_fill_solarized(guide = FALSE) +
  scale_colour_manual(guide = FALSE, values = rev(solarized_palette(7))) +
  xlab("") +
  scale_y_continuous(name = "Coefficient Estimate (Months/SD)")
```


```{r coefs_lexcat, fig.height=1.7, fig.width=7, fig.env='figure*', fig.align='center', dev='cairo_pdf', fig.cap='Estimates of predictor coefficients by lexical category, without any separation by language and omitting the three weaker predictors..'}
crossling_coefs %>%
  filter(term %in% c("frequency", "babiness", "concreteness", "mlu")) %>%
  mutate(term = factor(term, levels = rev(crossling_predictor_levels))) %>%
  ggplot(aes(x = term, y = estimate, colour = term)) +
    facet_wrap(~lexical_category, ncol = 4) +
    geom_pointrange(aes(ymin = estimate - 1.96 * std.error,
                        ymax = estimate + 1.96 * std.error)) +
    geom_hline(yintercept = 0, color = "grey", linetype = "dashed") +
    coord_flip() +
    scale_colour_manual(guide = FALSE, values = rev(solarized_palette(7))[4:7]) +
    xlab("") +
    scale_y_continuous(name = "Coefficient Estimate (Months/SD)")
```

## Predictors

Each of our predictors is derived from independent sources. For each word that appears on the CDI Word & Gestures form in each of our `r length(unique(lang_coef$language))` languages, we obtained an estimate of its frequency in child-directed speech, the mean utterance length of sentences in which if appears in child-directed speech, its length in characters, and ratings of its concreteness, valence, arousal, and relevance to babies. All items such as _child's own name_ were excluded. Examples of each of these predictors for English are shown in Table 2.

Frequency and MLU are measured relative to the word's language. But since extant datasets for conceptual ratings are primarily available for English, we mapped all words onto translation equivalents across CDI forms, allowing us to use the ratings for English words across languages. While necessarily imperfect, this method allows us to examine languages for which limited resources exist. Translation equivalents are available in the wordbank database using the \texttt{wordbankr} package [@frankinpress].

Each numeric predictor was centered and scaled so that all predictors would have comparable units. Finally, lexical category was determined on the basis of the conceptual categories presented on the CDI form (e.g., "Animals"), such that the noun category contained common nouns, predicates contained verbs and adjectives, function words contained closed-class words, and other contained the remaining items [following @bates1994].

### Frequency 

For each language, we estimated word frequency from unigram counts based on all corpora in the CHILDES database for that language. Each word's count includes the counts of words that share the same stem (so that _dogs_ counts as _dog_) or are synonymous (so that _father_ counts as _daddy_). For polysemous word pairs, such as _orange_ as in color and _orange_ as in fruit, the occurrences of _orange_ in the corpus were split uniformly between the two senses.\footnote{Polysemy is puzzle for our analysis because word sense disambiguation is not possible across languages. Our approach here is a pragmatic one, and should not affect our overall results given the relatively small number of polysemous words in each language.} Finally, counts were normalized to the length of each corpus and then log transformed. 

### MLU

For each language, we estimated each word's MLU by calculating the mean length in words of the sentences in which that word appeared, for all corpora in the CHILDES database for that language. Words that only occurred in one sentence were excluded.

### Length

We computed the number of characters in each word in each language. While imperfect, this metric of length is highly correlated with number of phonemes and syllables in each word [@lewisunderreview].

### Concreteness

We used previously collected norms for concreteness [@brysbaert2014], which were gathered by asking adult participants to rate how concrete the meaning of each word is on a 5-point scale from abstract to concrete. For the `r nrow(filter(uni_concreteness, is.na(concreteness))) - 2` CDI words that weren't part of the collected norms (mostly animal sounds such as _baa baa_), we imputed concreteness ratings as the mean of all other words' ratings.

### Valence and Arousal

We also used previously collected norms for valence and arousal [@warriner2013], for which adult participants are asked to rate words on a 1-9 happy-unhappy scale (valence) and 1-9 excited-calm scale (arousal). For the `r nrow(filter(uni_valences, is.na(valence))) - 2` CDI words that weren't part of the collected norms (mostly function words such as _her_), we imputed ratings from the mean of all CDI words' ratings.

### Babiness

Lastly, we used previously collected norms of "babiness," a measure of association with infancy [@perry2015] in which adult participants are asked to judge a word's relevance to babies.

# Analysis

An overview of our entire dataset can be seen in Figure \ref{fig:data}, which shows each word's estimated age of acquisition against its predictor values, separated by language and lexical category. We present three analyses of these data: 1) how predictor values change for words learned earlier and later, 2) their relative contributions to predicting AoA, and 3) their interaction with lexical category.

## Developmental Trajectories

To assess developmental trends, we examine how the values of each predictor change as a function of estimated AoA. Figure \ref{fig:devo} shows these trajectories, with a cubic curve smoothing over all words. Words that are learned earlier are more frequent, higher in babiness, and appear in shorter sentences. Concreteness exhibits a U-shaped trajectory, with the earliest learned words actually being relatively abstract (e.g., social routines and animal sounds).

## Predicting AoA

We fit a linear regression for each language's data, as well as a linear mixed-effects model with language as a random effect for all the data pooled across all languages. For illustrative purposes, Figure \ref{fig:fit} shows the predictions of the English model to the empirical AoA estimates.

Figure \ref{fig:coefs} shows the coefficient estimate for each predictor in each language and for all languages combined. We find that frequency, babiness, concreteness, and MLU are relatively stronger predictors of age of acquisition, across languages and in the all languages model. Overall there was considerable consistency in how the predictors pattern in various languages, although with some interesting differences. For example, MLU in English appears to be unusually strong, while frequency in Spanish look unusually weak. There is also variability in the overall fit of the models to the data, with some languages, such as Norwegian, having much more of the variance explained than others, such as Turkish.

## Lexical Category

Previous work gives reason to believe that predictors' relationship with age of acquisition differs among various lexical categories [@goodman2008]. To investigate these effects, we separated our data by lexical category and fit separate linear mixed-effects models for each. Figure \ref{fig:coefs_lexcat} shows the resulting coefficient estimates (leaving off the weaker predictors for illustrative purposes). Frequency mattered most for nouns and comparatively little for function words, while MLU was irrelevant for both nouns and predicates, but highly informative for function words and other items.


# Discussion

What makes words easier or harder for young children to learn? Previous experimental work has largely addressed this question using small-scale experiments. While such experiments can identify sources of variation, they typically do not allow for different sources to be compared in detail. In contrast, observational studies allow the effects of individual factors (with frequency being the most common) to be measured across ages and lexical categories [e.g., @goodman2008]. Scale comes at a cost in terms of detail, however: The availability of both predictors and outcome data has been quite limited. 

By including `r length(unique(lang_coef$language))` languages and as many predictors, our current work expands the scope of previous observational studies of age of acquisition. Our data show a number of patterns that confirm and expand previous reports. First, predictors differed in importance even very early development. For example, certain concepts that were more strongly associated with babies appeared to be learned early for children across languages [as in @tardif2008]. Second, we found general consistency in predictor coefficients across languages (even as overall model fit varied, at least in part due to the amount and quality of data for different languages). This consistency supports the idea that differences in culture or language structure do not lead to fundamentally different acquisition strategies, at least at the level of detail we were able to examine. 

Finally, the predictors varied in strength across lexical categories. Frequent, concrete nouns were learned earlier, consistent with theories that emphasize the importance of early referential speech [e.g., @baldwin1995]. But for predicates, concreteness was somewhat less important, and for function words, MLU was most predictive. Overall these findings are consistent with theories that emphasize the role of linguistic structure over conceptual complexity in the acquisition of other lexical categories beyond nouns [@gentner2001; @snedeker2007].

Despite its larger scope, our work still shares a number of important limitations with previous studies. First and foremost, our approach is to predict one set of individuals with data about the experience of a completely different set and ratings of concepts gathered from yet others. In contrast to dense-data approaches [@roy2015], this approach fundamentally limits the amount of variability we will be able to capture. In addition, the granularity of the predictors that can be extracted from corpus data and applied to every word is necessarily quite coarse. Ideally, predictors could be targeted more specifically at particular theoretical constructs of interest (for example, the patterns of use for particular predicates).

Perhaps the most important theoretical challenge in the study of early language is linking individual observations or experiments to the broader patterns of acquisition observed in large datasets. We have strong theories of how individual learning situations proceed [@frank2009; @mcmurray2012], and although we cannot yet discern unambiguous signatures of those theories in the large-scale data we have available, our analyses highlight the importance of studying aggregated data. They also demonstrate the value of analyzing a number of factors, including those predicted to be relevant by different and even competing theories.

Even for English, in which our seven predictors capture the most variance (r^2^ = 0.29), much still remains unexplained. Further, this variance is highly reliable -- cross-validation using half of the English-speaking children to predict ages of acquisition for the other half yields r^2^ = 0.98. While adjudicating between theories is a critical component of the scientific process, it is important not to forget that our working theories are incomplete [@breiman2001]. Unification across these theories may be the other critical step in making progress on understanding language learning [@newell1973].

```{r}
# Could cite  e.g. waxman vs. sloutsky on conceptual stuff in category learning if we want to talk about a specific case where adjudicating among two accounts has clearly gone wrong.
# 
# Also could cite e.g. Why We (Usually) Donâ€™t Have to Worry About Multiple Comparisons gelman et al., or anything else that points out that social science phenomena are likely to be multi-faceted and complex.
```


\vspace{1em}
\fbox{\parbox[b][][c]{7.3cm}{\centering All data and code for these analyses are available at\\ \url{https://github.com/mikabr/aoa-prediction}}}

# Acknowledgements

Thanks to the MacArthur-Bates CDI Advisory Board. This work supported by NSF BCS #1528526.

# References 

```{r}
# References will be generated automatically by Pandoc and included here.
# The following code is some latex to format the bibliography. Do not remove it.
```

\setlength{\parindent}{-0.1in} 
\setlength{\leftskip}{0.125in}
\noindent

